{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CbxiszMrlg9g"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle torch torchvision tqdm matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1️⃣ Download ImageNet-Mini from Kaggle ---\n",
        "!mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d ifigotin/imagenetmini-1000 -p /content\n",
        "!unzip -q /content/imagenetmini-1000.zip -d /content/imagenet-mini\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53YMrB22x50f",
        "outputId": "9b912033-4e49-454d-ef67-70b4be1cb933"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/ifigotin/imagenetmini-1000\n",
            "License(s): unknown\n",
            "Downloading imagenetmini-1000.zip to /content\n",
            "100% 3.91G/3.92G [00:53<00:00, 91.3MB/s]\n",
            "100% 3.92G/3.92G [00:53<00:00, 78.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2️⃣ Imports & configuration ---\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet50\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "NUM_CLASSES = 1000\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS =  100          # can scale to 100 on bigger HW\n",
        "MAX_LR = 0.1\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 1e-4\n",
        "LABEL_SMOOTH = 0.1"
      ],
      "metadata": {
        "id": "glGau6nV0Pvg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3️⃣ Transforms ---\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.4,0.4,0.4,0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
        "])"
      ],
      "metadata": {
        "id": "Htisc7KF0TtO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4️⃣ Datasets & Loaders ---\n",
        "train_ds = datasets.ImageFolder(\"/content/imagenet-mini/imagenet-mini/train\", transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(\"/content/imagenet-mini/imagenet-mini/val\",   transform=val_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "print(f\"✅ Loaded {len(train_ds)} train & {len(val_ds)} val samples.\")\n"
      ],
      "metadata": {
        "id": "k7lZQwfe05YU",
        "outputId": "27be7f3c-d310-4444-c73a-cbaf0d36f3f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 34745 train & 3923 val samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5️⃣ Model, optimizer, scheduler ---\n",
        "model = resnet50(weights=None, num_classes=NUM_CLASSES).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTH)\n",
        "optimizer = optim.SGD(model.parameters(), lr=MAX_LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, max_lr=MAX_LR,\n",
        "    steps_per_epoch=len(train_loader), epochs=EPOCHS,\n",
        "    pct_start=0.3, anneal_strategy='cos',\n",
        "    div_factor=25.0, final_div_factor=1e4\n",
        ")\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n"
      ],
      "metadata": {
        "id": "NDW_64AF0_DR",
        "outputId": "aa6aa087-0162-4a8a-d9dc-809a52da4e47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-608773024.py:13: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6️⃣ Training / evaluation ---\n",
        "def train_one_epoch(model, loader):\n",
        "    model.train()\n",
        "    run_loss = 0\n",
        "    for x,y in tqdm(loader, leave=False):\n",
        "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            out = model(x)\n",
        "            loss = criterion(out,y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "        run_loss += loss.item()\n",
        "    return run_loss/len(loader)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    tot, top1, top5 = 0,0,0\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "        out = model(x)\n",
        "        _,p1 = out.topk(1,1,True,True)\n",
        "        _,p5 = out.topk(5,1,True,True)\n",
        "        top1 += (p1.view(-1)==y).sum().item()\n",
        "        top5 += (p5==y.view(-1,1)).any(dim=1).sum().item()\n",
        "        tot  += y.size(0)\n",
        "    return top1/tot, top5/tot"
      ],
      "metadata": {
        "id": "j-kdGYCE1OLt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7️⃣ Main loop ---\n",
        "best=0; tr_losses=[]; val_top1s=[]; val_top5s=[]\n",
        "for ep in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {ep+1}/{EPOCHS}\")\n",
        "    tl=train_one_epoch(model,train_loader)\n",
        "    top1,top5=evaluate(model,val_loader)\n",
        "    tr_losses.append(tl); val_top1s.append(top1); val_top5s.append(top5)\n",
        "    print(f\"Loss {tl:.4f} | Val@1 {top1*100:.2f}% | Val@5 {top5*100:.2f}%\")\n",
        "    if top1>best:\n",
        "        best=top1; torch.save(model.state_dict(),\"resnet50_imagenetmini_best.pth\")\n",
        "        print(f\"✅ Saved new best (Top-1 {best*100:.2f}%)\")"
      ],
      "metadata": {
        "id": "CijsR7DC1Usw",
        "outputId": "32fd1460-0e42-4c27-ced9-307385ef43df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/272 [00:00<?, ?it/s]/tmp/ipython-input-1292186056.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            " 28%|██▊       | 77/272 [01:39<05:36,  1.73s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8️⃣ Visualization ---\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1); plt.plot(tr_losses); plt.title(\"Train Loss\")\n",
        "plt.subplot(1,2,2); plt.plot([v*100 for v in val_top1s],label=\"Top-1\")\n",
        "plt.plot([v*100 for v in val_top5s],label=\"Top-5\"); plt.legend(); plt.title(\"Validation Acc\")\n",
        "plt.show()\n",
        "print(f\"🏁 Best Top-1 {best*100:.2f}%\")"
      ],
      "metadata": {
        "id": "zpCTkJCf1XK3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}